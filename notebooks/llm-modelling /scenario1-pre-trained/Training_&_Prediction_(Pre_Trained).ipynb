{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP8UWYM8rManyHZkZZc5Pby"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **IMPORT LIBRARIES**"
      ],
      "metadata": {
        "id": "plcoKQnkQns4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNVc4aQcMtJC"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, PredefinedSplit\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import make_scorer, f1_score, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "lQ4i659oPGHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DEFINE FUNCTION**"
      ],
      "metadata": {
        "id": "gDLEC-EkhBGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define function to prepare data for logistic regression\n",
        "def prepare_data_for_logistic_regression(df):\n",
        "    # separate features and labels\n",
        "    features = df.filter(regex='^embedding_')\n",
        "    labels = df['price_direction']\n",
        "    return features, labels"
      ],
      "metadata": {
        "id": "DQmiUe49xgza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# custom F1 scorer with pos_label='positive'\n",
        "f1_scorer = make_scorer(f1_score, pos_label='positive')\n",
        "\n",
        "# define function to train with Randomized Search CV\n",
        "def train_model_with_randomsearch(train_features, train_labels, eval_features, eval_labels):\n",
        "\n",
        "    # define hyperparameter option\n",
        "    param_grid = {\n",
        "        'C': [0.5, 1, 5, 10],\n",
        "        'max_iter': [10000, 15000, 20000, 25000]}\n",
        "\n",
        "    # initiate model with lbfgs solver\n",
        "    model = LogisticRegression(solver='lbfgs')\n",
        "\n",
        "    # combine train and eval features and labels into single arrays\n",
        "    combined_features = np.vstack((train_features, eval_features))\n",
        "    combined_labels = np.hstack((train_labels, eval_labels))\n",
        "\n",
        "    # create a predefined split for cross validation (training & validation dataset)\n",
        "    test_fold = np.hstack((\n",
        "        np.full(train_features.shape[0], -1, dtype=int),\n",
        "        np.full(eval_features.shape[0], 0, dtype=int)\n",
        "    ))\n",
        "\n",
        "    ps = PredefinedSplit(test_fold)\n",
        "\n",
        "    # initiate randomized search\n",
        "    random_search = RandomizedSearchCV(model, param_grid, scoring=f1_scorer, cv=ps)\n",
        "    random_search.fit(combined_features, combined_labels)\n",
        "\n",
        "    return random_search.best_estimator_"
      ],
      "metadata": {
        "id": "UZ0PwtJDfVTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define rolling window training and prediction function\n",
        "def rolling_window_predictions(df):\n",
        "    # define the rolling windows\n",
        "    rolling_windows = [\n",
        "        (2005, 2013, 2014, 2015, [2016, 2017]),\n",
        "        (2007, 2015, 2016, 2017, [2018, 2019]),\n",
        "        (2009, 2017, 2018, 2019, [2020, 2021]),\n",
        "        (2011, 2019, 2020, 2021, [2022, 2023])\n",
        "    ]\n",
        "\n",
        "    # prepare results storage\n",
        "    results_accuracy = []\n",
        "    results_prediction = []\n",
        "\n",
        "    # iterate through each ticker\n",
        "    for company in df['permco'].unique():\n",
        "        print(f\"Processing company: {company}\")\n",
        "        company_df = df[df['permco'] == company]\n",
        "\n",
        "        # iterate through pre-set rolling window\n",
        "        for train_start, train_end, eval_start, eval_end, test_years in rolling_windows:\n",
        "\n",
        "            # define training period\n",
        "            train_period = (company_df['start_date'].dt.year >= train_start) & (company_df['start_date'].dt.year <= train_end)\n",
        "            train_data = company_df[train_period]\n",
        "\n",
        "            # define validation period\n",
        "            eval_period = (company_df['start_date'].dt.year >= eval_start) & (company_df['start_date'].dt.year <= eval_end)\n",
        "            eval_data = company_df[eval_period]\n",
        "\n",
        "            # skip the iteration if there's no data for training or evaluation\n",
        "            if train_data.empty or eval_data.empty:\n",
        "                continue\n",
        "\n",
        "            # prepare training and evaluation data for logistic regression\n",
        "            train_features, train_labels = prepare_data_for_logistic_regression(train_data)\n",
        "            eval_features, eval_labels = prepare_data_for_logistic_regression(eval_data)\n",
        "\n",
        "            # convert to numpy arrays\n",
        "            train_features = train_features.to_numpy()\n",
        "            eval_features = eval_features.to_numpy()\n",
        "            train_labels = train_labels.to_numpy()\n",
        "            eval_labels = eval_labels.to_numpy()\n",
        "\n",
        "            # train the logistic regression model with randomized search\n",
        "            best_model = train_model_with_randomsearch(train_features, train_labels, eval_features, eval_labels)\n",
        "\n",
        "            # iterate over each test year defined in the rolling window\n",
        "            for test_year in test_years:\n",
        "                test_period = (company_df['start_date'].dt.year == test_year)\n",
        "                test_data = company_df[test_period]\n",
        "\n",
        "                # skip the iteration if there's no data for testing\n",
        "                if test_data.empty:\n",
        "                    continue\n",
        "\n",
        "                # prepare test data for logistic regression\n",
        "                test_features, test_labels = prepare_data_for_logistic_regression(test_data)\n",
        "\n",
        "                # convert to numpy arrays\n",
        "                test_features = test_features.to_numpy()\n",
        "                test_labels = test_labels.to_numpy()\n",
        "\n",
        "                # make predictions\n",
        "                predictions = best_model.predict(test_features)\n",
        "                prob = best_model.predict_proba(test_features)\n",
        "\n",
        "                # evaluate the model\n",
        "                test_accuracy = accuracy_score(test_labels, predictions)\n",
        "\n",
        "                # store accuracy results\n",
        "                results_accuracy.append({\n",
        "                    'company': company,\n",
        "                    'train_period': f\"{train_start}-{train_end}\",\n",
        "                    'eval_period': f\"{eval_start}-{eval_end}\",\n",
        "                    'test_period': f\"{test_year}\",\n",
        "                    'test_accuracy': test_accuracy,  # Overall accuracy for the test period\n",
        "                })\n",
        "\n",
        "                # store prediction results\n",
        "                for idx in range(len(predictions)):\n",
        "                    results_prediction.append({\n",
        "                        'company': company,\n",
        "                        'week_date': test_data.iloc[idx]['start_date'],  # The specific date of the prediction\n",
        "                        'probability_neg': prob[idx][0].tolist(),  # Probability for the specific prediction\n",
        "                        'probability_pos': prob[idx][1].tolist(),\n",
        "                        'prediction': predictions[idx],  # Specific prediction\n",
        "                        'actual': test_data.iloc[idx]['price_direction']  # Actual value\n",
        "                    })\n",
        "\n",
        "                print(f\"Company: {company}, Train: {train_start}-{train_end}, Eval: {eval_start}-{eval_end}, \"\n",
        "                      f\"Test: {test_year}, Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "    return results_accuracy, results_prediction"
      ],
      "metadata": {
        "id": "utdsIairD290"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TRAINING AND PREDICTION**"
      ],
      "metadata": {
        "id": "WHzGYsbZrZOp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **BERT**"
      ],
      "metadata": {
        "id": "MippJqeiFvP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load training & test data embeddings\n",
        "file_path_train_bert = '/content/drive/MyDrive/PostGrad/5. Extended Research Projects/Embedding/Pre-Trained/bert_train_pretrained.csv'\n",
        "train_df_bert = pd.read_csv(file_path_train_bert)\n",
        "\n",
        "file_path_test_bert = '/content/drive/MyDrive/PostGrad/5. Extended Research Projects/Embedding/Pre-Trained/bert_test_pretrained.csv'\n",
        "test_df_bert = pd.read_csv(file_path_test_bert)\n",
        "\n",
        "# combine train and test dataset for rolling window\n",
        "final_df_bert = pd.concat([train_df_bert, test_df_bert], axis=0, ignore_index=True)\n",
        "\n",
        "# sort by permco and date\n",
        "final_df_bert.sort_values(by=['permco', 'start_date'], inplace=True)\n",
        "\n",
        "# format to datetime\n",
        "final_df_bert['start_date'] = pd.to_datetime(final_df_bert['start_date'], format='%Y-%m-%d')"
      ],
      "metadata": {
        "id": "obzrU99WWjzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# perform rolling window traning and predictions\n",
        "rolling_accuracy_bert, rolling_prediction_bert = rolling_window_predictions(final_df_bert)\n",
        "\n",
        "# convert results to dataframe\n",
        "rolling_accuracy_df_bert = pd.DataFrame(rolling_accuracy_bert)\n",
        "rolling_prediction_df_bert = pd.DataFrame(rolling_prediction_bert)"
      ],
      "metadata": {
        "id": "_o18jWvdtnBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define path to save results\n",
        "path_bert_accuracy = '/content/drive/MyDrive/PostGrad/5. Extended Research Projects/Results/Rolling Window Prediction/bert_rolling_accuracy.csv'\n",
        "path_bert_prediction = '/content/drive/MyDrive/PostGrad/5. Extended Research Projects/Results/Rolling Window Prediction/bert_rolling_prediction.csv'\n",
        "\n",
        "# save to csv\n",
        "rolling_accuracy_df_bert.to_csv(path_bert_accuracy, index=False)\n",
        "rolling_prediction_df_bert.to_csv(path_bert_prediction, index=False)"
      ],
      "metadata": {
        "id": "NMtiO5l4EEwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **RoBERTa**"
      ],
      "metadata": {
        "id": "5cLNEyitgIBo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load training & test data embeddings\n",
        "file_path_train_roberta = '/content/drive/MyDrive/PostGrad/5. Extended Research Projects/Embedding/Pre-Trained/roberta_train_pretrained.csv'\n",
        "train_df_roberta = pd.read_csv(file_path_train_roberta)\n",
        "\n",
        "file_path_test_roberta = '/content/drive/MyDrive/PostGrad/5. Extended Research Projects/Embedding/Pre-Trained/roberta_test_pretrained.csv'\n",
        "test_df_roberta = pd.read_csv(file_path_test_roberta)\n",
        "\n",
        "# combine train and test dataset for rolling window\n",
        "final_df_roberta = pd.concat([train_df_roberta, test_df_roberta], axis=0, ignore_index=True)\n",
        "\n",
        "# sort by permco and date\n",
        "final_df_roberta.sort_values(by=['permco', 'start_date'], inplace=True)\n",
        "\n",
        "# format to datetime\n",
        "final_df_roberta['start_date'] = pd.to_datetime(final_df_roberta['start_date'], format='%Y-%m-%d')"
      ],
      "metadata": {
        "id": "Maca7BD_iUm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# perform rolling window traning and predictions\n",
        "rolling_accuracy_roberta, rolling_prediction_roberta = rolling_window_predictions(final_df_roberta)\n",
        "\n",
        "# convert results to dataframe\n",
        "rolling_accuracy_df_roberta = pd.DataFrame(rolling_accuracy_roberta)\n",
        "rolling_prediction_df_roberta = pd.DataFrame(rolling_prediction_roberta)\n"
      ],
      "metadata": {
        "id": "O7R7jpO8iUm7",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define path to save results\n",
        "path_roberta_accuracy = '/content/drive/MyDrive/PostGrad/5. Extended Research Projects/Results/Rolling Window Prediction/roberta_rolling_accuracy.csv'\n",
        "path_roberta_prediction = '/content/drive/MyDrive/PostGrad/5. Extended Research Projects/Results/Rolling Window Prediction/roberta_rolling_prediction.csv'\n",
        "\n",
        "# save to csv\n",
        "rolling_accuracy_df_roberta.to_csv(path_roberta_accuracy, index=False)\n",
        "rolling_prediction_df_roberta.to_csv(path_roberta_prediction, index=False)"
      ],
      "metadata": {
        "id": "vOj4I5gLiUm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **DistilBERT**"
      ],
      "metadata": {
        "id": "x0dkduq038-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load training & test data embeddings\n",
        "file_path_train_distilbert = '/content/drive/MyDrive/PostGrad/5. Extended Research Projects/Embedding/Pre-Trained/distilbert_train_pretrained.csv'\n",
        "train_df_distilbert = pd.read_csv(file_path_train_distilbert)\n",
        "\n",
        "file_path_test_distilbert = '/content/drive/MyDrive/PostGrad/5. Extended Research Projects/Embedding/Pre-Trained/distilbert_test_pretrained.csv'\n",
        "test_df_distilbert = pd.read_csv(file_path_test_distilbert)\n",
        "\n",
        "# combine train and test dataset for rolling window\n",
        "final_df_distilbert = pd.concat([train_df_distilbert, test_df_distilbert], axis=0, ignore_index=True)\n",
        "\n",
        "# sort by permco and date\n",
        "final_df_distilbert.sort_values(by=['permco', 'start_date'], inplace=True)\n",
        "\n",
        "# format to datetime\n",
        "final_df_distilbert['start_date'] = pd.to_datetime(final_df_distilbert['start_date'], format='%Y-%m-%d')"
      ],
      "metadata": {
        "id": "pQwTbxQ338-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# perform rolling window traning and predictions\n",
        "rolling_accuracy_distilbert, rolling_prediction_distilbert = rolling_window_predictions(final_df_distilbert)\n",
        "\n",
        "# convert results to dataframe\n",
        "rolling_accuracy_df_distilbert = pd.DataFrame(rolling_accuracy_distilbert)\n",
        "rolling_prediction_df_distilbert = pd.DataFrame(rolling_prediction_distilbert)\n"
      ],
      "metadata": {
        "id": "-f6sPNt1EWqQ",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define path to save results\n",
        "path_distilbert_accuracy = '/content/drive/MyDrive/PostGrad/5. Extended Research Projects/Results/Rolling Window Prediction/distilbert_rolling_accuracy.csv'\n",
        "path_distilbert_prediction = '/content/drive/MyDrive/PostGrad/5. Extended Research Projects/Results/Rolling Window Prediction/distilbert_rolling_prediction.csv'\n",
        "\n",
        "# save to csv\n",
        "rolling_accuracy_df_distilbert.to_csv(path_distilbert_accuracy, index=False)\n",
        "rolling_prediction_df_distilbert.to_csv(path_distilbert_prediction, index=False)"
      ],
      "metadata": {
        "id": "K87iK0C7EWqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **DistilRoBERTa**"
      ],
      "metadata": {
        "id": "6XipIyYW4D0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load training & test data embeddings\n",
        "file_path_train_distilroberta = '/content/drive/MyDrive/PostGrad/5. Extended Research Projects/Embedding/Pre-Trained/distilroberta_train_pretrained.csv'\n",
        "train_df_distilroberta = pd.read_csv(file_path_train_distilroberta)\n",
        "\n",
        "file_path_test_distilroberta = '/content/drive/MyDrive/PostGrad/5. Extended Research Projects/Embedding/Pre-Trained/distilroberta_test_pretrained.csv'\n",
        "test_df_distilroberta = pd.read_csv(file_path_test_distilroberta)\n",
        "\n",
        "# combine train and test dataset for rolling window\n",
        "final_df_distilroberta = pd.concat([train_df_distilroberta, test_df_distilroberta], axis=0, ignore_index=True)\n",
        "\n",
        "# sort by permco and date\n",
        "final_df_distilroberta.sort_values(by=['permco', 'start_date'], inplace=True)\n",
        "\n",
        "# format to datetime\n",
        "final_df_distilroberta['start_date'] = pd.to_datetime(final_df_distilroberta['start_date'], format='%Y-%m-%d')"
      ],
      "metadata": {
        "id": "APSocUB14D1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# perform rolling window traning and predictions\n",
        "rolling_accuracy_distilroberta, rolling_prediction_distilroberta = rolling_window_predictions(final_df_distilroberta)\n",
        "\n",
        "# convert results to dataframe\n",
        "rolling_accuracy_df_distilroberta = pd.DataFrame(rolling_accuracy_distilroberta)\n",
        "rolling_prediction_df_distilroberta = pd.DataFrame(rolling_prediction_distilroberta)\n"
      ],
      "metadata": {
        "id": "l8ygjyteE0JR",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define path to save results\n",
        "path_distilroberta_accuracy = '/content/drive/MyDrive/PostGrad/5. Extended Research Projects/Results/Rolling Window Prediction/distilroberta_rolling_accuracy.csv'\n",
        "path_distilroberta_prediction = '/content/drive/MyDrive/PostGrad/5. Extended Research Projects/Results/Rolling Window Prediction/distilroberta_rolling_prediction.csv'\n",
        "\n",
        "# save to csv\n",
        "rolling_accuracy_df_distilroberta.to_csv(path_distilroberta_accuracy, index=False)\n",
        "rolling_prediction_df_distilroberta.to_csv(path_distilroberta_prediction, index=False)"
      ],
      "metadata": {
        "id": "nKp7Y6mpE0JR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **FinBERT**"
      ],
      "metadata": {
        "id": "zeGTLehbBlXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load training & test data embeddings\n",
        "file_path_train_finbert = '/content/drive/MyDrive/PostGrad/5. Extended Research Projects/Embedding/Pre-Trained/finbert_train_pretrained.csv'\n",
        "train_df_finbert = pd.read_csv(file_path_train_finbert)\n",
        "\n",
        "file_path_test_finbert = '/content/drive/MyDrive/PostGrad/5. Extended Research Projects/Embedding/Pre-Trained/finbert_test_pretrained.csv'\n",
        "test_df_finbert = pd.read_csv(file_path_test_finbert)\n",
        "\n",
        "# combine train and test dataset for rolling window\n",
        "final_df_finbert = pd.concat([train_df_finbert, test_df_finbert], axis=0, ignore_index=True)\n",
        "\n",
        "# sort by permco and date\n",
        "final_df_finbert.sort_values(by=['permco', 'start_date'], inplace=True)\n",
        "\n",
        "# format to datetime\n",
        "final_df_finbert['start_date'] = pd.to_datetime(final_df_finbert['start_date'], format='%Y-%m-%d')"
      ],
      "metadata": {
        "id": "xS-0iVcTBlXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# perform rolling window traning and predictions\n",
        "rolling_accuracy_finbert, rolling_prediction_finbert = rolling_window_predictions(final_df_finbert)\n",
        "\n",
        "# convert results to dataframe\n",
        "rolling_accuracy_df_finbert = pd.DataFrame(rolling_accuracy_finbert)\n",
        "rolling_prediction_df_finbert = pd.DataFrame(rolling_prediction_finbert)\n"
      ],
      "metadata": {
        "id": "2YVt1CvxBlXe",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define path to save results\n",
        "path_finbert_accuracy = '/content/drive/MyDrive/PostGrad/5. Extended Research Projects/Results/Rolling Window Prediction/finbert_rolling_accuracy.csv'\n",
        "path_finbert_prediction = '/content/drive/MyDrive/PostGrad/5. Extended Research Projects/Results/Rolling Window Prediction/finbert_rolling_prediction.csv'\n",
        "\n",
        "# save to csv\n",
        "rolling_accuracy_df_finbert.to_csv(path_finbert_accuracy, index=False)\n",
        "rolling_prediction_df_finbert.to_csv(path_finbert_prediction, index=False)"
      ],
      "metadata": {
        "id": "NFT9H9t5BlXg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}